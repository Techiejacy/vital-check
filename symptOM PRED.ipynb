{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "072474b9-1d5e-45ec-bc20-a7c9c784f1be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'dataset.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m pd.set_option(\u001b[33m'\u001b[39m\u001b[33mdisplay.max_columns\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m#sym_path = \"../data/raw/symptomdatas/\"\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m#loading the datasets\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m sym_dataset = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdataset.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m sym_desc = pd.read_csv( \u001b[33m\"\u001b[39m\u001b[33msymptom_Description.csv\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     14\u001b[39m sym_prec = pd.read_csv( \u001b[33m\"\u001b[39m\u001b[33msymptom_precaution.csv\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'dataset.csv'"
     ]
    }
   ],
   "source": [
    "# Basic imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# For wider display\n",
    "pd.set_option('display.max_columns', None)\n",
    "#sym_path = \"../data/raw/symptomdatas/\"\n",
    "#loading the datasets\n",
    "sym_dataset = pd.read_csv( \"dataset.csv\")\n",
    "sym_desc = pd.read_csv( \"symptom_Description.csv\")\n",
    "sym_prec = pd.read_csv( \"symptom_precaution.csv\")\n",
    "sym_severity = pd.read_csv( \"Symptom-severity.csv\")\n",
    "\n",
    "# Preview\n",
    "sym_dataset.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb2ee03-5951-4474-b41e-53db5c2a580f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sym_dataset.shape)\n",
    "sym_dataset.info()\n",
    "sym_dataset.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735811fb-7035-4865-a79d-02791a8ad11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sym_dataset = sym_dataset.fillna(\"None\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3efdf8-42cd-4159-92ce-eba34c8480f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "symptom_cols = [col for col in sym_dataset.columns if col.startswith(\"Symptom\")]\n",
    "sym_dataset[\"all_symptoms\"] = sym_dataset[symptom_cols].values.tolist()\n",
    "\n",
    "sym_dataset[[\"Disease\", \"all_symptoms\"]].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e416928d-9074-438e-aff4-1cbfc07d29be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1Ô∏è‚É£ Ensure all_symptoms is converted to list properly\n",
    "sym_dataset[\"all_symptoms\"] = sym_dataset[\"all_symptoms\"].apply(\n",
    "    lambda s: str(s).replace(\" \", \"\").split(\",\")\n",
    ")\n",
    "\n",
    "# 2Ô∏è‚É£ Remove \"None\" and empty values\n",
    "sym_dataset[\"all_symptoms\"] = sym_dataset[\"all_symptoms\"].apply(\n",
    "    lambda s: [x for x in s if x and x.lower() != \"none\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67666761-8365-469e-adf8-60922862549f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sym_dataset[\"all_symptoms\"].head(10))\n",
    "#sym_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5953636-36a6-47f4-9343-27bc5ca400e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "symptom_cols = [col for col in sym_dataset.columns if col.startswith(\"Symptom\")]\n",
    "\n",
    "sym_dataset[\"all_symptoms\"] = (\n",
    "    sym_dataset[symptom_cols]\n",
    "    .apply(lambda row: [x for x in row if x and x != \"None\"], axis=1)\n",
    ")\n",
    "sym_dataset[[\"Disease\", \"all_symptoms\"]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd7d764-815d-4a56-89fd-0efa9a397e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean symptom names (strip spaces and fix formatting)\n",
    "def clean_symptom_list(sym_list):\n",
    "    cleaned = []\n",
    "    for s in sym_list:\n",
    "        s = s.strip()               # remove leading/trailing spaces\n",
    "        s = s.replace(\"  \", \" \")    # fix double spaces\n",
    "        s = s.replace(\" _\", \"_\")    # fix misplaced underscores\n",
    "        s = s.replace(\" _\", \"_\")\n",
    "        cleaned.append(s)\n",
    "    return cleaned\n",
    "\n",
    "sym_dataset[\"all_symptoms\"] = sym_dataset[\"all_symptoms\"].apply(clean_symptom_list)\n",
    "\n",
    "# Preview 10 rows again\n",
    "sym_dataset[[\"Disease\", \"all_symptoms\"]].sample(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902d5c80-df37-4b81-b685-22805c52eac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all unique symptoms across all rows\n",
    "all_symptoms_set = set()\n",
    "for symptoms in sym_dataset[\"all_symptoms\"]:\n",
    "    all_symptoms_set.update(symptoms)\n",
    "\n",
    "all_symptoms = sorted(list(all_symptoms_set))\n",
    "len(all_symptoms), all_symptoms[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f780ef-2fbf-4395-936b-9b33dbc8e935",
   "metadata": {},
   "outputs": [],
   "source": [
    "sym_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b77913-8258-4916-8fa4-8a8107dffa2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(\"--- üè• DATA READINESS CHECK ---\")\n",
    "\n",
    "# 1. CHECK SHAPE (Volume)\n",
    "rows, cols = sym_dataset.shape\n",
    "print(f\"1. Row Count: {rows}\")\n",
    "if rows < 4000:\n",
    "    print(\"   ‚ö†Ô∏è WARNING: Your data looks shrunk! Did you drop duplicates? (Expected ~4920)\")\n",
    "else:\n",
    "    print(\"   ‚úÖ SUCCESS: Full patient volume preserved.\")\n",
    "\n",
    "# 2. CHECK TEXT CONSISTENCY (Spot Check)\n",
    "# We look at the first symptom column to see if text is clean (no spaces, lowercase).\n",
    "# Adjust 'Symptom_1' to whatever your first symptom column is named.\n",
    "check_col = [c for c in sym_dataset.columns if 'Symptom' in c][0] \n",
    "sample_val = sym_dataset[check_col].iloc[0]\n",
    "\n",
    "print(f\"\\n2. Text Format Check (Sample from {check_col}): '{sample_val}'\")\n",
    "if \" \" in str(sample_val) and \"_\" not in str(sample_val):\n",
    "    print(\"   ‚ö†Ô∏è WARNING: Found spaces. Recommended to replace with underscores (e.g., 'skin rash' -> 'skin_rash').\")\n",
    "elif str(sample_val).lower() != str(sample_val):\n",
    "    print(\"   ‚ö†Ô∏è WARNING: Found uppercase letters. Recommended to lowercase everything.\")\n",
    "else:\n",
    "    print(\"   ‚úÖ SUCCESS: Text looks standardized (lowercase/formatted).\")\n",
    "\n",
    "# 3. CHECK MISSING VALUES\n",
    "# It is NORMAL to have NaNs in symptom columns (not everyone has every symptom).\n",
    "# We just want to make sure the 'Disease' column is full.\n",
    "missing_diseases = sym_dataset['Disease'].isnull().sum()\n",
    "print(f\"\\n3. Missing Diseases: {missing_diseases}\")\n",
    "if missing_diseases > 0:\n",
    "    print(\"   üö® CRITICAL: You have rows with no Disease label. Drop them.\")\n",
    "else:\n",
    "    print(\"   ‚úÖ SUCCESS: All rows have a target disease.\")\n",
    "\n",
    "print(\"-\" * 30)\n",
    "print(\"VERDICT:\")\n",
    "if rows > 4000 and missing_diseases == 0:\n",
    "    print(\"üöÄ READY FOR STEP 4 (Convert to Numbers)\")\n",
    "else:\n",
    "    print(\"‚ùå NOT READY. Fix the issues above.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbd98ce-d6c1-4ac4-adec-9cbd573b5435",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"--- üîÑ MASTER FIX: BINARY ENCODING & RANDOM FOREST ---\")\n",
    "\n",
    "# 1. DEFINE COLUMNS\n",
    "symptom_cols = [col for col in sym_dataset.columns if 'Symptom' in col]\n",
    "FINAL_Y_COL = 'Disease'\n",
    "\n",
    "# 2. CLEAN DATA\n",
    "df_processed = sym_dataset.copy()\n",
    "for col in symptom_cols:\n",
    "    df_processed[col] = df_processed[col].astype(str).str.strip().str.replace(' ', '_').str.lower().replace('none', '')\n",
    "\n",
    "# Add ID\n",
    "df_processed['Instance_ID'] = df_processed.index \n",
    "\n",
    "# 3. BINARY TRANSFORMATION (The Robust Fix)\n",
    "print(\"Transforming to Binary (1/0)...\")\n",
    "df_long = pd.melt(\n",
    "    df_processed,\n",
    "    id_vars=['Instance_ID', FINAL_Y_COL], \n",
    "    value_vars=symptom_cols,\n",
    "    value_name='Symptom'\n",
    ")\n",
    "# Filter out empty\n",
    "df_long = df_long[df_long['Symptom'] != ''].copy()\n",
    "\n",
    "# *** FIX: IGNORE WEIGHTS. SET ALL PRESENT SYMPTOMS TO 1 ***\n",
    "df_long['Present'] = 1\n",
    "\n",
    "# Pivot\n",
    "X_binary = df_long.pivot_table(\n",
    "    index='Instance_ID', \n",
    "    columns='Symptom',\n",
    "    values='Present',\n",
    "    fill_value=0, # Fill missing symptoms with 0\n",
    "    aggfunc='max'\n",
    ")\n",
    "\n",
    "# Align Y\n",
    "Y_binary = df_processed.set_index('Instance_ID')[FINAL_Y_COL].loc[X_binary.index]\n",
    "\n",
    "# Define X and Y\n",
    "X = X_binary\n",
    "Y = Y_binary\n",
    "\n",
    "print(f\"‚úÖ Data Prepared. X Shape: {X.shape}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# 4. TRAIN RANDOM FOREST\n",
    "print(\"Training Random Forest...\")\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X.values, Y.values, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=Y.values\n",
    ")\n",
    "\n",
    "rf_model_base = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model_base.fit(X_train, Y_train)\n",
    "\n",
    "# 5. EVALUATE\n",
    "acc = rf_model_base.score(X_test, Y_test)\n",
    "print(f\"\\nüèÜ MODEL ACCURACY: {acc:.4f}\")\n",
    "\n",
    "# Save variables for the Risk Step\n",
    "Y_pred_proba = rf_model_base.predict_proba(X_test)\n",
    "disease_labels = rf_model_base.classes_\n",
    "\n",
    "print(\"‚úÖ Model Ready for Risk Integration.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3119276-762c-42a7-8bd4-f2afd59ca956",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- SIMPLE TEST FUNCTION ---\n",
    "def test_model_prediction(symptom_list, model, feature_columns):\n",
    "    \"\"\"\n",
    "    Creates a binary input vector from a list of symptoms and asks the model to predict.\n",
    "    \"\"\"\n",
    "    # 1. Create an empty row (all 0s)\n",
    "    input_data = {col: 0 for col in feature_columns}\n",
    "    \n",
    "    # 2. Mark the input symptoms as 1 (Present)\n",
    "    # We handle potential spelling mismatches by checking if the column exists\n",
    "    found_symptoms = []\n",
    "    for s in symptom_list:\n",
    "        # Clean the input string to match column format (lowercase, underscore)\n",
    "        clean_s = s.strip().replace(' ', '_').lower()\n",
    "        if clean_s in input_data:\n",
    "            input_data[clean_s] = 1\n",
    "            found_symptoms.append(clean_s)\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Warning: Symptom '{s}' not found in model features.\")\n",
    "            \n",
    "    # 3. Convert to DataFrame for prediction\n",
    "    input_df = pd.DataFrame([input_data])\n",
    "    \n",
    "    # 4. Predict\n",
    "    prediction = model.predict(input_df.values)[0]\n",
    "    probability = np.max(model.predict_proba(input_df.values)[0])\n",
    "    \n",
    "    return prediction, probability, found_symptoms\n",
    "\n",
    "# --- TEST CASES ---\n",
    "\n",
    "# TEST 1: Malaria Symptoms\n",
    "malaria_symptoms = ['chills', 'vomiting', 'high_fever', 'sweating', 'headache', 'nausea']\n",
    "pred, prob, found = test_model_prediction(malaria_symptoms, rf_model_base, X.columns)\n",
    "\n",
    "print(\"\\n--- TEST 1: MALARIA SYMPTOMS ---\")\n",
    "print(f\"Input Symptoms Found: {found}\")\n",
    "print(f\"Model Prediction: {pred}\")\n",
    "print(f\"Confidence: {prob:.2%}\")\n",
    "\n",
    "# TEST 2: Allergy Symptoms\n",
    "allergy_symptoms = ['continuous_sneezing', 'shivering', 'chills', 'watering_from_eyes']\n",
    "pred2, prob2, found2 = test_model_prediction(allergy_symptoms, rf_model_base, X.columns)\n",
    "\n",
    "print(\"\\n--- TEST 2: ALLERGY SYMPTOMS ---\")\n",
    "print(f\"Input Symptoms Found: {found2}\")\n",
    "print(f\"Model Prediction: {pred2}\")\n",
    "print(f\"Confidence: {prob2:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a9b11c-f42f-4875-afc7-312828260f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# --- CONFUSION MATRIX DIAGNOSTIC ---\n",
    "\n",
    "# 1. Generate Predictions\n",
    "# FIX: X_test is already an array, so we remove .values\n",
    "Y_pred = rf_model_base.predict(X_test)\n",
    "\n",
    "# 2. Get the Unique Labels (Sorted)\n",
    "# This forces the X-axis and Y-axis to use the exact same order,\n",
    "# which creates the perfect diagonal line if the model is accurate.\n",
    "unique_labels = sorted(rf_model_base.classes_)\n",
    "\n",
    "# 3. Plot with Explicit Labels\n",
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "\n",
    "ConfusionMatrixDisplay.from_predictions(\n",
    "    Y_test, \n",
    "    Y_pred, \n",
    "    labels=unique_labels,  # <--- Force alignment\n",
    "    cmap=plt.cm.Blues,\n",
    "    xticks_rotation='vertical',\n",
    "    normalize='true', # Shows percentages (0.0 to 1.0)\n",
    "    ax=ax,\n",
    "    include_values=False # Hides numbers to make the pattern clearer\n",
    ")\n",
    "\n",
    "plt.title(\"Diagnostic Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc35466-8322-4c91-8b14-59ccfe44e571",
   "metadata": {},
   "outputs": [],
   "source": [
    "sym_dataset['Disease'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fa0e39-965f-4a0b-add8-62b9e66be176",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.countplot(x='Disease', data=sym_dataset)\n",
    "plt.xticks(rotation=90) # Rotates names so you can read them\n",
    "plt.title(\"Disease Distribution (Checking for Balance)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d267596-7b49-4c2d-a192-103635f7f275",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "print(\"--- üè• PHASE 4: WHO RISK INTEGRATION ---\")\n",
    "\n",
    "# ==========================================\n",
    "# 1. LOAD WHO DATA\n",
    "# ==========================================\n",
    "# Adjust this path if your file is named differently\n",
    "who_file_path = \"../data/processed/who_mortality_sample.csv\" \n",
    "\n",
    "try:\n",
    "    # Attempt to load from file\n",
    "    sampled_df = pd.read_csv(who_file_path)\n",
    "    print(f\"‚úÖ WHO Data Loaded. Shape: {sampled_df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ö†Ô∏è File not found at {who_file_path}\")\n",
    "    print(\"   Checking variables... if 'sampled_df' is already in memory, we will use it.\")\n",
    "    if 'sampled_df' not in locals():\n",
    "        raise ValueError(\"üö® WHO Data not found! Please load your WHO csv file.\")\n",
    "\n",
    "# ==========================================\n",
    "# 2. CALCULATE RISK SCORES\n",
    "# ==========================================\n",
    "WHO_CAUSE_COL = 'Cause'\n",
    "\n",
    "# Ensure death columns are numeric\n",
    "death_cols = [c for c in sampled_df.columns if 'Deaths' in c]\n",
    "for col in death_cols:\n",
    "    sampled_df[col] = pd.to_numeric(sampled_df[col], errors='coerce').fillna(0)\n",
    "\n",
    "# Sum deaths per row (Total deaths for that specific record)\n",
    "sampled_df['Total_Deaths'] = sampled_df[death_cols].sum(axis=1)\n",
    "\n",
    "# Group by ICD Code (Cause) and sum total deaths\n",
    "who_agg = sampled_df.groupby(WHO_CAUSE_COL)['Total_Deaths'].sum().reset_index()\n",
    "\n",
    "# Normalize: Score between 0 and 1 (1 = The Deadliest Disease)\n",
    "who_agg['Risk_Score'] = who_agg['Total_Deaths'] / who_agg['Total_Deaths'].max()\n",
    "WHO_Risk_DF = who_agg[[WHO_CAUSE_COL, 'Risk_Score']]\n",
    "\n",
    "print(f\"‚úÖ WHO Risk Scores Calculated for {len(WHO_Risk_DF)} causes.\")\n",
    "print(\"   Top 3 Riskiest Codes in Sample:\")\n",
    "print(WHO_Risk_DF.sort_values('Risk_Score', ascending=False).head(3))\n",
    "\n",
    "# ==========================================\n",
    "# 3. DEFINE MANUAL MAPPING (Disease -> ICD)\n",
    "# ==========================================\n",
    "disease_to_who_map = {\n",
    "    '(vertigo) Paroymsal  Positional Vertigo': 'H81', \n",
    "    'AIDS': 'B24', \n",
    "    'Acne': 'L70', \n",
    "    'Alcoholic hepatitis': 'K70.1', \n",
    "    'Allergy': 'J30', \n",
    "    'Arthritis': 'M13.9', \n",
    "    'Bronchial Asthma': 'J45', \n",
    "    'Cervical spondylosis': 'M47.9', \n",
    "    'Chicken pox': 'B01', \n",
    "    'Chronic cholestasis': 'K76.9', \n",
    "    'Common Cold': 'J00', \n",
    "    'Dengue': 'A90', \n",
    "    'Diabetes ': 'E14', \n",
    "    'Dimorphic hemmorhoids(piles)': 'I84', \n",
    "    'Drug Reaction': 'T88.7', \n",
    "    'Fungal infection': 'B49', \n",
    "    'GERD': 'K21.9', \n",
    "    'Gastroenteritis': 'A09', \n",
    "    'Heart attack': 'I21', \n",
    "    'Hepatitis B': 'B18.1', \n",
    "    'Hepatitis C': 'B18.2', \n",
    "    'Hepatitis D': 'B18.8', \n",
    "    'Hepatitis E': 'B18.8', \n",
    "    'Hypertension ': 'I10', \n",
    "    'Hyperthyroidism': 'E05.9', \n",
    "    'Hypoglycemia': 'E16.2', \n",
    "    'Hypothyroidism': 'E03.9', \n",
    "    'Impetigo': 'L01', \n",
    "    'Jaundice': 'R17', \n",
    "    'Malaria': 'B54', \n",
    "    'Migraine': 'G43.9', \n",
    "    'Osteoarthristis': 'M19.9', \n",
    "    'Paralysis (brain hemorrhage)': 'I61.9', \n",
    "    'Peptic ulcer diseae': 'K27.9', \n",
    "    'Pneumonia': 'J18.9', \n",
    "    'Psoriasis': 'L40.9', \n",
    "    'Tuberculosis': 'A16.9', \n",
    "    'Typhoid': 'A01.0', \n",
    "    'Urinary tract infection': 'N39.0', \n",
    "    'Varicose veins': 'I83.9', \n",
    "    'hepatitis A': 'B15.9'\n",
    "}\n",
    "print(\"‚úÖ Disease Mapping Dictionary Ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd018290-8479-4d2d-bf61-3075029f8a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- üöÄ BUILDING THE FINAL APPLICATION LAYER ---\n",
      "‚úÖ System is LIVE. Ready for testing.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "print(\"--- üöÄ BUILDING THE FINAL APPLICATION LAYER ---\")\n",
    "\n",
    "# --- 1. HELPER: SAFE REMEDY FORMATTER ---\n",
    "# Keeps original medical advice but makes it sound professional.\n",
    "def format_remedy_list_SAFE(raw_precaution_list):\n",
    "    if not isinstance(raw_precaution_list, list) or not raw_precaution_list:\n",
    "        return [\"Consult a medical professional.\"]\n",
    "\n",
    "    formatted = []\n",
    "    for phrase in raw_precaution_list:\n",
    "        if isinstance(phrase, str) and phrase.strip():\n",
    "            # Capitalize and add period\n",
    "            clean = phrase.strip()[0].upper() + phrase.strip()[1:]\n",
    "            if not clean.endswith('.'): clean += '.'\n",
    "            formatted.append(clean)\n",
    "    \n",
    "    # Add standard disclaimer\n",
    "    formatted.append(\"If symptoms persist or worsen, seek immediate medical attention.\")\n",
    "    return list(set(formatted))\n",
    "\n",
    "# --- 2. THE SMART PREDICTION FUNCTION ---\n",
    "def predict_disease_smart(user_symptoms, top_k=5):\n",
    "    \"\"\"\n",
    "    Full Pipeline: Input -> Binary Vector -> Model Prob -> Risk Adjust -> Output\n",
    "    \"\"\"\n",
    "    \n",
    "    # A. INPUT PREPARATION\n",
    "    # Create zero vector matching the model's training features (X)\n",
    "    # We use a try/except block in case X is not globally defined, checking rf_model_base features\n",
    "    try:\n",
    "        feature_names = X.columns\n",
    "    except NameError:\n",
    "        # Fallback if X variable is lost but model exists\n",
    "        feature_names = rf_model_base.feature_names_in_\n",
    "\n",
    "    input_data = {col: 0 for col in feature_names}\n",
    "    \n",
    "    matched_symptoms = []\n",
    "    for s in user_symptoms:\n",
    "        # Clean input to match feature names\n",
    "        clean_s = s.strip().replace(' ', '_').lower()\n",
    "        \n",
    "        # Exact match check\n",
    "        if clean_s in input_data:\n",
    "            input_data[clean_s] = 1\n",
    "            matched_symptoms.append(clean_s)\n",
    "        # Loose match check (e.g. \"fever\" matches \"high_fever\")\n",
    "        else:\n",
    "            for col in feature_names:\n",
    "                if clean_s in col:\n",
    "                    input_data[col] = 1\n",
    "                    matched_symptoms.append(col)\n",
    "                    \n",
    "    # B. GET RAW PROBABILITIES\n",
    "    # Suppress warnings about feature names\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        input_vector = pd.DataFrame([input_data]).values\n",
    "        probabilities = rf_model_base.predict_proba(input_vector)[0]\n",
    "    \n",
    "    disease_labels = rf_model_base.classes_\n",
    "    \n",
    "    # C. APPLY WHO RISK ADJUSTMENT\n",
    "    # Map Model Labels -> ICD Codes -> Risk Scores\n",
    "    risk_lookup = pd.Series(disease_labels).map(disease_to_who_map)\n",
    "    \n",
    "    # Get Risk Scores from the WHO dataframe\n",
    "    Risk_Score_Series = WHO_Risk_DF.set_index(WHO_CAUSE_COL)['Risk_Score']\n",
    "    \n",
    "    # Create the Risk Vector (filling unknowns with a tiny score)\n",
    "    min_risk = Risk_Score_Series.min() if not Risk_Score_Series.empty else 0.00001\n",
    "    risk_vector = risk_lookup.map(Risk_Score_Series).fillna(min_risk).values\n",
    "    \n",
    "    # THE CORE FORMULA\n",
    "    adjusted_scores = probabilities * risk_vector\n",
    "    \n",
    "    # D. RANK AND FORMAT OUTPUT\n",
    "    top_indices = np.argsort(adjusted_scores)[::-1][:top_k]\n",
    "    \n",
    "    results = []\n",
    "    for i in top_indices:\n",
    "        d_name = disease_labels[i]\n",
    "        \n",
    "        # Lookup formatting\n",
    "        lookup_key = d_name.lower().replace(' ', '_').replace('(', '').replace(')', '').strip('_')\n",
    "        \n",
    "        # 1. Get Description\n",
    "        try: \n",
    "            desc = sym_desc.loc[sym_desc['Disease'] == lookup_key, 'Description'].values[0]\n",
    "        except: \n",
    "            desc = \"Description unavailable.\"\n",
    "            \n",
    "        # 2. Get Precautions\n",
    "        try:\n",
    "            pre_row = sym_prec.loc[sym_prec[\"Disease\"] == lookup_key]\n",
    "            raw_prec = pre_row.iloc[0][1:].dropna().tolist()\n",
    "            pre = format_remedy_list_SAFE(raw_prec)\n",
    "        except:\n",
    "            pre = [\"Consult a doctor.\"]\n",
    "            \n",
    "        results.append({\n",
    "            \"Disease\": d_name,\n",
    "            \"Smart Score\": round(adjusted_scores[i], 5),\n",
    "            \"Raw Probability\": f\"{probabilities[i]*100:.1f}%\",\n",
    "            \"Description\": desc,\n",
    "            \"Remedies\": pre\n",
    "        })\n",
    "        \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "print(\"‚úÖ System is LIVE. Ready for testing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56f7bf53-93a3-49c8-b40a-0ca3b6a3f9aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- üß™ FINAL DIAGNOSIS TEST ---\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'rf_model_base' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 35\u001b[39m, in \u001b[36mpredict_disease_smart\u001b[39m\u001b[34m(user_symptoms, top_k)\u001b[39m\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m     feature_names = \u001b[43mX\u001b[49m.columns\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNameError\u001b[39;00m:\n\u001b[32m     37\u001b[39m     \u001b[38;5;66;03m# Fallback if X variable is lost but model exists\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'X' is not defined",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m test_symptoms = [\u001b[33m'\u001b[39m\u001b[33mhigh_fever\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mchills\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mcough\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mbreathlessness\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mfatigue\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- üß™ FINAL DIAGNOSIS TEST ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m df_result = \u001b[43mpredict_disease_smart\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_symptoms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Display nicely\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mIPython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdisplay\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m display\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 38\u001b[39m, in \u001b[36mpredict_disease_smart\u001b[39m\u001b[34m(user_symptoms, top_k)\u001b[39m\n\u001b[32m     35\u001b[39m     feature_names = X.columns\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNameError\u001b[39;00m:\n\u001b[32m     37\u001b[39m     \u001b[38;5;66;03m# Fallback if X variable is lost but model exists\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m     feature_names = \u001b[43mrf_model_base\u001b[49m.feature_names_in_\n\u001b[32m     40\u001b[39m input_data = {col: \u001b[32m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m feature_names}\n\u001b[32m     42\u001b[39m matched_symptoms = []\n",
      "\u001b[31mNameError\u001b[39m: name 'rf_model_base' is not defined"
     ]
    }
   ],
   "source": [
    "# Test: Respiratory Symptoms (Could be Cold, could be Pneumonia)\n",
    "test_symptoms = ['high_fever', 'chills', 'cough', 'breathlessness', 'fatigue']\n",
    "\n",
    "print(\"\\n--- üß™ FINAL DIAGNOSIS TEST ---\")\n",
    "df_result = predict_disease_smart(test_symptoms)\n",
    "\n",
    "# Display nicely\n",
    "from IPython.display import display\n",
    "display(df_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee71306-e873-4336-80e0-db194c4eeb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "print(\"--- üõ†Ô∏è FIXING THE SYMPTOM MATCHER ---\")\n",
    "\n",
    "# 1. INSPECT THE ACTUAL FEATURES\n",
    "# Let's see what the model is actually expecting.\n",
    "model_features = list(X.columns)\n",
    "print(f\"Model expects {len(model_features)} symptoms. Examples: {model_features[:5]}\")\n",
    "\n",
    "def predict_disease_ROBUST(user_symptoms, top_k=5):\n",
    "    # 1. Input Preparation (The Robust Matcher)\n",
    "    input_data = {col: 0 for col in model_features}\n",
    "    matched_list = []\n",
    "    \n",
    "    print(f\"\\nüîç Scanning for symptoms: {user_symptoms}\")\n",
    "    \n",
    "    for s in user_symptoms:\n",
    "        # Clean user input\n",
    "        clean_s = s.strip().lower().replace(' ', '_')\n",
    "        \n",
    "        found = False\n",
    "        # Strategy 1: Exact Match\n",
    "        if clean_s in input_data:\n",
    "            input_data[clean_s] = 1\n",
    "            matched_list.append(f\"{s} (Exact)\")\n",
    "            found = True\n",
    "            \n",
    "        # Strategy 2: Loose Match (Substring)\n",
    "        # If \"fever\" is typed, it catches \"high_fever\"\n",
    "        if not found:\n",
    "            for col in model_features:\n",
    "                if clean_s in col or col in clean_s:\n",
    "                    input_data[col] = 1\n",
    "                    matched_list.append(f\"{col} (Matched via '{s}')\")\n",
    "                    found = True\n",
    "    \n",
    "    print(f\"‚úÖ MATCHED FEATURES: {matched_list}\")\n",
    "    \n",
    "    if not matched_list:\n",
    "        print(\"‚ùå ERROR: No symptoms matched! The model is guessing blindly.\")\n",
    "        return None\n",
    "\n",
    "    # 2. Predict Probabilities\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        input_vector = pd.DataFrame([input_data]).values\n",
    "        probs = rf_model_base.predict_proba(input_vector)[0]\n",
    "    \n",
    "    disease_labels = rf_model_base.classes_\n",
    "    \n",
    "    # 3. Apply Risk (The Boost Formula)\n",
    "    risk_lookup = pd.Series(disease_labels).map(disease_to_who_map)\n",
    "    Risk_Score_Series_ICD = WHO_Risk_DF.set_index(WHO_CAUSE_COL)['Risk_Score']\n",
    "    min_risk = 0.0\n",
    "    risk_vector = risk_lookup.map(Risk_Score_Series_ICD).fillna(min_risk).values\n",
    "    \n",
    "    # Boost Score = Prob * (1 + Risk)\n",
    "    adjusted_scores = probs * (1 + risk_vector)\n",
    "    \n",
    "    # 4. Rank\n",
    "    top_indices = np.argsort(adjusted_scores)[::-1][:top_k]\n",
    "    \n",
    "    results = []\n",
    "    for i in top_indices:\n",
    "        d_name = disease_labels[i]\n",
    "        \n",
    "        # Lookup Description\n",
    "        lookup = d_name.lower().replace(' ', '_').replace('(', '').replace(')', '').strip('_')\n",
    "        try: desc = sym_desc.loc[sym_desc['Disease'] == lookup, 'Description'].values[0]\n",
    "        except: desc = \"N/A\"\n",
    "        \n",
    "        try: \n",
    "            pre_row = sym_prec.loc[sym_prec[\"Disease\"] == lookup]\n",
    "            pre = pre_row.iloc[0][1:].dropna().tolist()\n",
    "        except: pre = [\"Consult Doctor\"]\n",
    "            \n",
    "        results.append({\n",
    "            \"Disease\": d_name,\n",
    "            \"Final Score\": round(adjusted_scores[i], 4),\n",
    "            \"Raw Probability\": f\"{probs[i]*100:.1f}%\",\n",
    "            \"Description\": desc,\n",
    "            \"Remedies\": pre\n",
    "        })\n",
    "        \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# --- TEST RUN ---\n",
    "test_symptoms = ['high_fever', 'chills', 'cough', 'breathlessness', 'fatigue']\n",
    "result = predict_disease_ROBUST(test_symptoms)\n",
    "\n",
    "if result is not None:\n",
    "    display(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56e1d19-f437-4974-b0e7-1f2913e4407e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(\"--- üßπ FINAL COSMETIC FIX: DESCRIPTIONS ---\")\n",
    "\n",
    "# 1. RELOAD REFERENCE TABLES\n",
    "# We load fresh to avoid any previous cleaning confusion\n",
    "sym_desc = pd.read_csv(\"../data/raw/symptomdatas/symptom_Description.csv\")\n",
    "sym_prec = pd.read_csv(\"../data/raw/symptomdatas/symptom_precaution.csv\")\n",
    "\n",
    "# 2. CLEAN THE KEYS TO MATCH MODEL\n",
    "# Model predicts: \"Bronchial Asthma\" -> We convert to \"bronchial_asthma\" for lookup\n",
    "# So we must ensure the reference tables use \"bronchial_asthma\" too.\n",
    "def clean_key(text):\n",
    "    return str(text).lower().strip().replace(' ', '_').replace('(', '').replace(')', '')\n",
    "\n",
    "sym_desc['Disease_Key'] = sym_desc['Disease'].apply(clean_key)\n",
    "sym_prec['Disease_Key'] = sym_prec['Disease'].apply(clean_key)\n",
    "\n",
    "# 3. UPDATE THE PREDICTION FUNCTION LOOKUP\n",
    "# We update the function one last time to use this new 'Disease_Key' column\n",
    "def predict_final_display(user_symptoms, top_k=5):\n",
    "    # (Reuse existing prediction logic from predict_disease_ROBUST)\n",
    "    result_df = predict_disease_ROBUST(user_symptoms, top_k)\n",
    "    \n",
    "    # Post-process for descriptions\n",
    "    if result_df is not None and not result_df.empty:\n",
    "        clean_descs = []\n",
    "        clean_precs = []\n",
    "        \n",
    "        for disease in result_df['Disease']:\n",
    "            lookup = clean_key(disease)\n",
    "            \n",
    "            # Description Lookup\n",
    "            try: \n",
    "                d = sym_desc.loc[sym_desc['Disease_Key'] == lookup, 'Description'].values[0]\n",
    "            except: d = \"Description not found.\"\n",
    "            clean_descs.append(d)\n",
    "            \n",
    "            # Precaution Lookup\n",
    "            try:\n",
    "                p_row = sym_prec.loc[sym_prec['Disease_Key'] == lookup].iloc[0, 1:].dropna().tolist()\n",
    "                # Basic formatting\n",
    "                p_fmt = [x.strip().capitalize() for x in p_row]\n",
    "                p_str = \", \".join(p_fmt)\n",
    "            except: p_str = \"Consult doctor.\"\n",
    "            clean_precs.append(p_str)\n",
    "            \n",
    "        result_df['Description'] = clean_descs\n",
    "        result_df['Remedies'] = clean_precs\n",
    "        \n",
    "    return result_df\n",
    "\n",
    "# --- RUN FINAL TEST ---\n",
    "test_symptoms = ['high_fever', 'chills', 'cough', 'breathlessness', 'fatigue']\n",
    "print(\"\\n--- ‚ú® FINAL PROJECT OUTPUT ---\")\n",
    "final_table = predict_final_display(test_symptoms)\n",
    "display(final_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56031a3-e6fa-40c1-a43b-ed0fb2dd7769",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13447448-2e27-4b5e-ac2d-f5be7f5fe760",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf8cff3-2106-4ff8-8c42-dd88f7589c5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1478b9a6-f05d-4fb8-88e7-07ee07a36e68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4e6c4d-c22c-41c6-8ad2-88add38df179",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "47e46e24-db28-42f5-8880-105c1f38f6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_state = {\n",
    "    \"symptoms\":[],\n",
    "    \"history\":[]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8d92f69b-0d3f-471f-87f9-c8474406f354",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYMPTOM_SYNONYMS = {\n",
    "    \"fever\": [\"hot body\", \"high temperature\", \"temperature\", \"hotness\", \"heat\"],\n",
    "    \"chills\": [\"cold\", \"shivering\", \"freezing\"],\n",
    "    \"fatigue\": [\"weak\", \"tired\", \"exhausted\"],\n",
    "    \"nausea\": [\"vomiting\", \"feel like vomiting\", \"urge to vomit\", \"queasy\"],\n",
    "    \"headache\": [\"head pain\", \"migraine\", \"pounding head\"]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2efccabc-0a36-4ccf-a624-b95a96b5f0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_symptoms(user_text):\n",
    "    detected = []\n",
    "    text = user_text.lower()\n",
    "\n",
    "    for symp, syn_list in SYMPTOM_SYNONYMS.items():\n",
    "        if symp in text:\n",
    "            detected.append(symp)\n",
    "        else:\n",
    "            for s in syn_list:\n",
    "                if s in text:\n",
    "                    detected.append(symp)\n",
    "                    break\n",
    "    return detected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "026550e7-32ba-4a89-ae72-54ab55e18ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_conversation(user_text):\n",
    "    new_symptoms = extract_symptoms(user_text)\n",
    "    \n",
    "    for s in new_symptoms:\n",
    "        if s not in conversation_state[\"symptoms\"]:\n",
    "            conversation_state[\"symptoms\"].append(s)\n",
    "    \n",
    "    conversation_state[\"history\"].append(user_text)\n",
    "    \n",
    "    return new_symptoms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b53cd4a0-1323-4f54-ba3d-690c18fe81ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save only the model\n",
    "with open(\"smarthealth_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(rf_model_base, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3c7b5e4e-785f-4d70-a641-6418a343e2d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ smarthealth_features.pkl saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# After you have your X from training\n",
    "import pickle\n",
    "\n",
    "# Suppose X is your training dataframe with 131 features\n",
    "model_features = list(X.columns)\n",
    "\n",
    "# Save to a pickle file\n",
    "with open(\"smarthealth_features.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model_features, f)\n",
    "\n",
    "print(\"‚úÖ smarthealth_features.pkl saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "49b0bad1-f13c-4d84-a870-f35d94828194",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(X.values, columns=X_binary.columns).to_csv(\"smarthealth_X_train.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d08e688-d54d-4057-a620-f5c6dfe2cc60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2e20d7-ceb8-4c1d-8f72-7d882c2c4c3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a4f45e-334f-4f32-89e0-5a380d175ff4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "31e3f53a-d6c7-47f6-9456-41c90f5987ec",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4213025606.py, line 203)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[42]\u001b[39m\u001b[32m, line 203\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31m```\u001b[39m\n    ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"--- üöÄ INITIALIZING FINAL MEDICAL AGENT SYSTEM ---\")\n",
    "\n",
    "# ==========================================\n",
    "# STEP 1: THE SYNONYM MATCHER (Natural Language Engine)\n",
    "# ==========================================\n",
    "symptom_synonyms = {\n",
    "    # General Pain\n",
    "    'ache': 'pain', 'hurts': 'pain', 'sore': 'pain', 'painful': 'pain',\n",
    "    \n",
    "    # Stomach/Abdominal\n",
    "    'stomach_ache': 'stomach_pain', 'belly_ache': 'stomach_pain', 'tummy_pain': 'stomach_pain',\n",
    "    'bloated': 'stomach_pain', 'abdominal': 'abdominal_pain',\n",
    "    \n",
    "    # Respiratory\n",
    "    'hard_to_breathe': 'breathlessness', 'short_of_breath': 'breathlessness', 'panting': 'breathlessness',\n",
    "    'runny_nose': 'runny_nose', 'sneezing': 'continuous_sneezing', 'phlegm': 'phlegm',\n",
    "    \n",
    "    # Temperature/Infection\n",
    "    'shivering': 'chills', 'cold': 'chills', 'freezing': 'chills',\n",
    "    'hot': 'high_fever', 'burning': 'high_fever', 'temp': 'high_fever', 'fever': 'high_fever',\n",
    "    'sweat': 'sweating',\n",
    "    \n",
    "    # Digestion\n",
    "    'puke': 'vomiting', 'throw_up': 'vomiting', 'nauseous': 'nausea',\n",
    "    'poop': 'diarrhoea', 'loose_motion': 'diarrhoea',\n",
    "    \n",
    "    # Neurological/General\n",
    "    'dizzy': 'dizziness', 'spinning': 'dizziness', 'lightheaded': 'dizziness',\n",
    "    'weak': 'fatigue', 'tired': 'fatigue', 'exhausted': 'fatigue',\n",
    "    'confused': 'altered_sensorium',\n",
    "    \n",
    "    # Skin\n",
    "    'rash': 'skin_rash', 'itch': 'itching', 'scratch': 'itching', 'spots': 'nodal_skin_eruptions'\n",
    "}\n",
    "\n",
    "def extract_features(user_text, model_columns):\n",
    "    \"\"\"Step 1 Logic: Convert User Text -> Model Features\"\"\"\n",
    "    user_text = user_text.lower().strip()\n",
    "    found_features = set()\n",
    "    \n",
    "    # A. Synonym Mapping\n",
    "    for phrase, mapped_col in symptom_synonyms.items():\n",
    "        if phrase in user_text:\n",
    "            found_features.add(mapped_col)\n",
    "            \n",
    "    # B. Direct Matching (Fuzzy)\n",
    "    # Check if any actual column name appears in the text\n",
    "    for col in model_columns:\n",
    "        clean_col = col.replace('_', ' ')\n",
    "        if clean_col in user_text or col in user_text:\n",
    "            found_features.add(col)\n",
    "            \n",
    "    return list(found_features)\n",
    "\n",
    "print(\"‚úÖ Step 1: Synonym Engine Ready.\")\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# STEP 2: CALIBRATED CLASSIFIER (Probability Correction)\n",
    "# ==========================================\n",
    "# Random Forest is confident but often wrong about probability (e.g. says 0.9 when it means 0.6).\n",
    "# Calibration fixes this so 80% confidence actually means 80% chance.\n",
    "\n",
    "print(\"\\n--- STEP 2 & 3: TRAINING CALIBRATED MODEL ---\")\n",
    "\n",
    "# 1. Split Data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X.values, Y.values, test_size=0.2, random_state=42, stratify=Y.values\n",
    ")\n",
    "\n",
    "# 2. Base Model\n",
    "base_rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# 3. Calibrated Wrapper (Sigmoid Calibration)\n",
    "calibrated_model = CalibratedClassifierCV(base_rf, method='sigmoid', cv=5)\n",
    "calibrated_model.fit(X_train, Y_train)\n",
    "\n",
    "print(\"‚úÖ Step 2: Model Calibrated & Trained.\")\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# STEP 3: CROSS-VALIDATION (Robustness Check)\n",
    "# ==========================================\n",
    "# Verify the model is stable across different data splits\n",
    "\n",
    "cv_scores = cross_val_score(calibrated_model, X.values, Y.values, cv=5, scoring='accuracy')\n",
    "print(f\"‚úÖ Step 3: Cross-Validation Accuracy: {cv_scores.mean():.4f} (+/- {cv_scores.std()*2:.4f})\")\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# STEP 4 & 5: THE AGENT CLASS (Low Confidence Rejection + Response)\n",
    "# ==========================================\n",
    "\n",
    "class Dr_AI_Advanced:\n",
    "    def __init__(self, model, feature_cols, who_risk_df, map_dict, desc_df, prec_df):\n",
    "        self.model = model\n",
    "        self.cols = feature_cols\n",
    "        self.who_risk = who_risk_df.set_index('Cause')['Risk_Score']\n",
    "        self.mapping = map_dict\n",
    "        self.desc = desc_df\n",
    "        self.prec = prec_df\n",
    "        \n",
    "        # Calculate Disease Profiles (for Relevance Scoring)\n",
    "        # (Assuming sym_dataset is available globally, or passed in. \n",
    "        # Ideally passed in, but using global for brevity here)\n",
    "        self.disease_profiles = {}\n",
    "        for d in Y.unique():\n",
    "             # Get symptoms that happen > 0 times for this disease\n",
    "             d_rows = X[Y == d]\n",
    "             symptoms = d_rows.columns[d_rows.sum() > 0].tolist()\n",
    "             self.disease_profiles[d] = symptoms\n",
    "\n",
    "    def consult(self, user_input):\n",
    "        # A. EXTRACT\n",
    "        symptoms = extract_features(user_input, self.cols)\n",
    "        \n",
    "        if not symptoms:\n",
    "            return \"I couldn't detect any specific symptoms. Please describe your physical condition (e.g., 'I have a headache and fever').\"\n",
    "            \n",
    "        # Prepare Input Vector\n",
    "        input_data = np.zeros((1, len(self.cols)))\n",
    "        for s in symptoms:\n",
    "            if s in self.cols:\n",
    "                idx = list(self.cols).index(s)\n",
    "                input_data[0, idx] = 1\n",
    "        \n",
    "        # B. PREDICT\n",
    "        probs = self.model.predict_proba(input_data)[0]\n",
    "        classes = self.model.classes_\n",
    "        \n",
    "        # C. CALCULATE SCORES (Risk + Relevance)\n",
    "        final_scores = []\n",
    "        \n",
    "        for i, disease in enumerate(classes):\n",
    "            prob = probs[i]\n",
    "            \n",
    "            # 1. Risk Boost\n",
    "            try:\n",
    "                icd = self.mapping.get(disease)\n",
    "                risk_val = self.who_risk.get(icd, 0.0)\n",
    "            except: risk_val = 0.0\n",
    "            \n",
    "            # 2. Relevance (Symptom Overlap)\n",
    "            # How many of the User's symptoms fit this Disease's profile?\n",
    "            profile = self.disease_profiles.get(disease, [])\n",
    "            matches = sum(1 for s in symptoms if s in profile)\n",
    "            relevance = matches / len(symptoms) if len(symptoms) > 0 else 0\n",
    "            \n",
    "            # MASTER FORMULA:\n",
    "            # Score = Probability * (1 + Risk) * (1 + Relevance^2)\n",
    "            # Relevance is squared to heavily punish diseases that don't match the symptoms.\n",
    "            score = prob * (1 + risk_val) * (1 + (relevance**2))\n",
    "            \n",
    "            final_scores.append(score)\n",
    "            \n",
    "        # D. SELECT WINNER\n",
    "        best_idx = np.argmax(final_scores)\n",
    "        winner = classes[best_idx]\n",
    "        confidence = probs[best_idx]\n",
    "        \n",
    "        # STEP 4: LOW CONFIDENCE REJECTION\n",
    "        # If the model is less than 20% sure, do not guess.\n",
    "        if confidence < 0.20:\n",
    "            return (f\"‚ö†Ô∏è **Uncertain Diagnosis**\\n\"\n",
    "                    f\"My analysis is inconclusive (Confidence: {confidence*100:.1f}%). \"\n",
    "                    f\"Your symptoms ({', '.join(symptoms)}) do not strongly match any specific profile in my database. \"\n",
    "                    f\"Please provide more details or consult a doctor.\")\n",
    "\n",
    "        # STEP 5: POLISHED RESPONSE TEMPLATE\n",
    "        lookup = winner.lower().replace(' ', '_').replace('(', '').replace(')', '').strip('_')\n",
    "        try: d_text = self.desc.loc[self.desc['Disease'] == lookup, 'Description'].values[0]\n",
    "        except: d_text = \"Details unavailable.\"\n",
    "        \n",
    "        try: \n",
    "            p_row = self.prec.loc[self.prec['Disease'] == lookup].iloc[0, 1:].dropna().tolist()\n",
    "            remedies = \", \".join([x.strip().capitalize() for x in p_row])\n",
    "        except: remedies = \"Consult doctor.\"\n",
    "\n",
    "        return (f\"ü©∫ **DIAGNOSIS REPORT**\\n\"\n",
    "                f\"--------------------------------\\n\"\n",
    "                f\"**Detected:** {winner}\\n\"\n",
    "                f\"**Certainty:** {confidence*100:.1f}% (Risk-Adjusted)\\n\\n\"\n",
    "                f\"**Why this result?**\\n\"\n",
    "                f\"You reported *{', '.join(symptoms)}*. This pattern strongly matches {winner}, \"\n",
    "                f\"and I have prioritized it based on clinical risk factors.\\n\\n\"\n",
    "                f\"**Overview:**\\n{d_text}\\n\\n\"\n",
    "                f\"**Recommended Actions:**\\n{remedies}\\n\"\n",
    "                f\"--------------------------------\\n\"\n",
    "                f\"(‚ö†Ô∏è AI Recommendation Only. Not a substitute for professional medical advice.)\")\n",
    "\n",
    "# --- INSTANTIATE ---\n",
    "agent = Dr_AI_Advanced(calibrated_model, X.columns, WHO_Risk_DF, disease_to_who_map, sym_desc, sym_prec)\n",
    "print(\"‚úÖ Final Agent Online.\")\n",
    "```\n",
    "\n",
    "### üß™ How to Test Your Final System\n",
    "\n",
    "Use these lines to verify the steps:\n",
    "\n",
    "```python\n",
    "# 1. Test the \"Rejection\" (Step 4)\n",
    "print(agent.consult(\"I have a weird feeling in my toe\")) \n",
    "# Expect: \"Uncertain Diagnosis\" because 'toe' isn't in your symptoms.\n",
    "\n",
    "# 2. Test the \"Smart Logic\" (Risk + Relevance)\n",
    "print(bot.consult(\"I have a high fever and I am shivering\"))\n",
    "# Expect: Malaria (because shivering->chills matches Malaria's profile perfectly)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe8fb77-1b4f-47f4-9fc6-f9d245b08fae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ca4c199f-26bb-4495-bd58-1e6ef725aa17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Agent Upgrade Complete: Ready for Natural Language.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import re  # Regex for text cleaning\n",
    "import warnings\n",
    "\n",
    "class DrAI_Agent:\n",
    "    def __init__(self, model, feature_columns, who_risk_df, mapping, desc_df, prec_df):\n",
    "        self.model = model\n",
    "        self.features = feature_columns\n",
    "        self.who_risk = who_risk_df.set_index('Cause')['Risk_Score']\n",
    "        self.mapping = mapping\n",
    "        self.desc_df = desc_df\n",
    "        self.prec_df = prec_df\n",
    "        \n",
    "        # üß† SYNONYM DICTIONARY: Translates human speak to model speak\n",
    "        self.synonyms = {\n",
    "            'ache': 'pain', 'aching': 'pain', 'hurt': 'pain',\n",
    "            'dizzleness': 'dizziness', 'dizzy': 'dizziness', 'spinning': 'dizziness',\n",
    "            'puke': 'vomiting', 'throw up': 'vomiting', 'vomit': 'vomiting',\n",
    "            'hot': 'fever', 'temperature': 'fever', 'burning': 'fever',\n",
    "            'shiver': 'shivering', 'cold': 'chills',\n",
    "            'tired': 'fatigue', 'exhausted': 'fatigue', 'weak': 'fatigue',\n",
    "            'breathing': 'breathlessness', 'breath': 'breathlessness',\n",
    "            'rash': 'skin_rash', 'spots': 'nodal_skin_eruptions',\n",
    "            'belly': 'stomach', 'tummy': 'stomach'\n",
    "        }\n",
    "        \n",
    "        self.greetings = [\"Hello, I've analyzed your narrative.\", \"I have processed your symptoms.\"]\n",
    "        self.concerns = [\"However, I am prioritizing a critical risk.\", \"I am flagging a serious possibility.\"]\n",
    "\n",
    "    def _extract_symptoms_from_text(self, text):\n",
    "        \"\"\"\n",
    "        The NLP Brain: Converts a sentence into a list of dataset features.\n",
    "        \"\"\"\n",
    "        # 1. Clean Text: Lowercase, remove punctuation\n",
    "        text = text.lower()\n",
    "        text = re.sub(r'[^\\w\\s]', ' ', text) # Remove punctuation\n",
    "        \n",
    "        # 2. Tokenize and Apply Synonyms\n",
    "        words = text.split()\n",
    "        cleaned_words = [self.synonyms.get(w, w) for w in words]\n",
    "        processed_text = \" \" + \" \".join(cleaned_words) + \" \" # Add padding for matching\n",
    "        \n",
    "        # 3. Match against Model Features (X.columns)\n",
    "        matched_features = []\n",
    "        \n",
    "        for feature in self.features:\n",
    "            # Create variations of the feature name to search for\n",
    "            # e.g., 'stomach_pain' -> matches \"stomach pain\", \"stomach_pain\"\n",
    "            feature_clean = feature.replace('_', ' ')\n",
    "            \n",
    "            # Split feature into core keywords (e.g., \"stomach\", \"pain\")\n",
    "            keywords = feature.split('_')\n",
    "            \n",
    "            # LOGIC: If ALL keywords of a feature exist in the text, it's a match\n",
    "            # Example: \"stomach aches\" -> \"stomach pain\" -> contains \"stomach\" AND \"pain\" -> Match!\n",
    "            if all(k in processed_text for k in keywords):\n",
    "                matched_features.append(feature)\n",
    "            elif feature in processed_text: # Direct match\n",
    "                matched_features.append(feature)\n",
    "                \n",
    "        return list(set(matched_features)) # Remove duplicates\n",
    "\n",
    "    def _generate_reasoning(self, top_disease, raw_prob, is_risk_intervention):\n",
    "        intro = random.choice(self.greetings)\n",
    "        if is_risk_intervention:\n",
    "            return (f\"{intro}\\n\\n\"\n",
    "                    f\"Based purely on the symptoms you described, this statistically looks like a common condition. \"\n",
    "                    f\"{random.choice(self.concerns)} \"\n",
    "                    f\"I have elevated **{top_disease}** to the top of your diagnosis list.\\n\\n\"\n",
    "                    f\"üß† **My Reasoning:** While the raw statistical match is {raw_prob}, \"\n",
    "                    f\"the mortality risk associated with {top_disease} is too high to ignore. \"\n",
    "                    f\"Safety first.\")\n",
    "        else:\n",
    "            return (f\"{intro}\\n\\n\"\n",
    "                    f\"I am diagnosing **{top_disease}** with a raw confidence of {raw_prob}. \"\n",
    "                    f\"Your description aligns strongly with the clinical patterns for this condition.\")\n",
    "\n",
    "    def consult(self, user_input):\n",
    "        # 1. NLP Extraction\n",
    "        matched_symptoms = self._extract_symptoms_from_text(user_input)\n",
    "        \n",
    "        if not matched_symptoms:\n",
    "            print(\"--- ü©∫ Dr. AI ---\")\n",
    "            print(\"I read your message, but I couldn't identify specific symptoms I recognize.\")\n",
    "            print(\"Could you list them more simply? (e.g., 'I have a fever and headache')\")\n",
    "            return\n",
    "\n",
    "        # 2. Prepare Vector\n",
    "        input_data = {col: 0 for col in self.features}\n",
    "        for s in matched_symptoms:\n",
    "            input_data[s] = 1\n",
    "        \n",
    "        # 3. Predict (Brain)\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            input_vector = pd.DataFrame([input_data]).values\n",
    "            probs = self.model.predict_proba(input_vector)[0]\n",
    "        \n",
    "        labels = self.model.classes_\n",
    "        \n",
    "        # 4. Risk Adjustment (Wisdom)\n",
    "        risk_vector = pd.Series(labels).map(self.mapping).map(self.who_risk).fillna(0.00001).values\n",
    "        adjusted_scores = probs * (1 + risk_vector) # Boost Formula\n",
    "        \n",
    "        # 5. Decision\n",
    "        raw_winner_idx = np.argmax(probs)\n",
    "        smart_winner_idx = np.argmax(adjusted_scores)\n",
    "        \n",
    "        raw_winner = labels[raw_winner_idx]\n",
    "        smart_winner = labels[smart_winner_idx]\n",
    "        \n",
    "        is_risk_intervention = (raw_winner != smart_winner)\n",
    "        \n",
    "        # 6. Report\n",
    "        print(\"--- ü©∫ Dr. AI Medical Report ---\")\n",
    "        print(f\"üìù **I extracted these symptoms from your story:**\\n   {', '.join(matched_symptoms)}\\n\")\n",
    "        \n",
    "        print(self._generate_reasoning(smart_winner, f\"{probs[smart_winner_idx]*100:.1f}%\", is_risk_intervention))\n",
    "        \n",
    "        # Details\n",
    "        lookup = smart_winner.lower().replace(' ', '_').replace('(', '').replace(')', '').strip('_')\n",
    "        try:\n",
    "            desc = self.desc_df.loc[self.desc_df['Disease'] == lookup, 'Description'].values[0]\n",
    "            print(f\"\\nüìò **What is it?**\\n{desc}\")\n",
    "        except: pass\n",
    "        \n",
    "        try:\n",
    "            p_row = self.prec_df.loc[self.prec_df['Disease'] == lookup].iloc[0, 1:].dropna().tolist()\n",
    "            # Quick formatting\n",
    "            pre = [x.strip().capitalize() for x in p_row]\n",
    "            print(f\"\\nüõ°Ô∏è **Immediate Recommendations:**\")\n",
    "            for p in pre: print(f\"- {p}.\")\n",
    "        except: pass\n",
    "        \n",
    "        print(\"\\n(‚ö†Ô∏è Disclaimer: I am an AI. Please visit a real doctor for confirmation.)\")\n",
    "\n",
    "# --- INSTANTIATE THE AGENT ---\n",
    "agent = DrAI_Agent(rf_model_base, X.columns, WHO_Risk_DF, disease_to_who_map, sym_desc, sym_prec)\n",
    "print(\"‚úÖ Agent Upgrade Complete: Ready for Natural Language.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2a81868e-8d76-4818-8abf-52b290ae3b8a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sentence_transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[41]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer, util\n\u001b[32m      4\u001b[39m model_emb = SentenceTransformer(\u001b[33m'\u001b[39m\u001b[33mall-MiniLM-L6-v2\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Your symptom list\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'sentence_transformers'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "model_emb = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Your symptom list\n",
    "symptoms_db = list(X.columns)\n",
    "\n",
    "symptom_embeddings = model_emb.encode(symptoms_db, convert_to_tensor=True)\n",
    "\n",
    "def expand_and_match_symptoms(user_text):\n",
    "    user_embedding = model_emb.encode(user_text, convert_to_tensor=True)\n",
    "\n",
    "    scores = util.cos_sim(user_embedding, symptom_embeddings)[0]\n",
    "    top_indices = scores.argsort(descending=True)\n",
    "\n",
    "    matched = []\n",
    "    for idx in top_indices[:10]:   # top matches\n",
    "        if float(scores[idx]) > 0.45:  # threshold\n",
    "            matched.append(symptoms_db[idx])\n",
    "\n",
    "    return list(set(matched))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ee62cea0-fbe6-4251-983b-c92ff2fe6e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ü©∫ Dr. AI Medical Report ---\n",
      "üìù **I extracted these symptoms from your story:**\n",
      "   dizziness, fatigue\n",
      "\n",
      "I have processed your symptoms.\n",
      "\n",
      "I am diagnosing **Cervical spondylosis** with a raw confidence of 26.0%. Your description aligns strongly with the clinical patterns for this condition.\n",
      "\n",
      "üìò **What is it?**\n",
      "Cervical spondylosis is a general term for age-related wear and tear affecting the spinal disks in your neck. As the disks dehydrate and shrink, signs of osteoarthritis develop, including bony projections along the edges of bones (bone spurs).\n",
      "\n",
      "üõ°Ô∏è **Immediate Recommendations:**\n",
      "- Use heating pad or cold pack.\n",
      "- Exercise.\n",
      "- Take otc pain reliver.\n",
      "- Consult doctor.\n",
      "\n",
      "(‚ö†Ô∏è Disclaimer: I am an AI. Please visit a real doctor for confirmation.)\n"
     ]
    }
   ],
   "source": [
    "# --- TEST WITH NATURAL LANGUAGE ---\n",
    "\n",
    "# Your complex user story\n",
    "user_story = \"i have been having a bit fatigued and dizzleness every early hours of the morning and then my stomach aches, what do you think is is wrong with me and what are the preacautions i should take\"\n",
    "\n",
    "# Run the consultation\n",
    "agent.consult(user_story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a3b0d5-ebf2-4005-bd27-2a2721f742fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949c1031-9362-42cf-96af-b4e5de9b8a15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "330a480a-3082-44a9-8402-b16eb24005c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Context-Aware Agent Online.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "class DrAI_Context_Agent:\n",
    "    def __init__(self, model, feature_columns, who_risk_df, mapping, desc_df, prec_df):\n",
    "        self.model = model\n",
    "        self.features = feature_columns\n",
    "        self.who_risk = who_risk_df.set_index('Cause')['Risk_Score']\n",
    "        self.mapping = mapping\n",
    "        self.desc_df = desc_df\n",
    "        self.prec_df = prec_df\n",
    "        \n",
    "        # 1. SYMPTOM TRANSLATOR (Human -> Dataset)\n",
    "        self.synonyms = {\n",
    "            'ache': 'pain', 'aching': 'pain', 'hurt': 'pain',\n",
    "            'dizzleness': 'dizziness', 'dizzy': 'dizziness', 'spinning': 'dizziness',\n",
    "            'puke': 'vomiting', 'throw up': 'vomiting', 'vomit': 'vomiting',\n",
    "            'hot': 'fever', 'temperature': 'fever', 'burning': 'fever',\n",
    "            'shiver': 'shivering', 'cold': 'chills',\n",
    "            'tired': 'fatigue', 'exhausted': 'fatigue', 'weak': 'fatigue',\n",
    "            'breathing': 'breathlessness', 'breath': 'breathlessness',\n",
    "            'rash': 'skin_rash', 'spots': 'nodal_skin_eruptions',\n",
    "            'belly': 'stomach', 'tummy': 'stomach', 'bloated': 'stomach_pain' \n",
    "        }\n",
    "        \n",
    "        # 2. CONTEXT PATTERNS (The \"Detail\" Catcher)\n",
    "        self.context_patterns = {\n",
    "            'Time': ['morning', 'night', 'evening', 'afternoon', 'waking up', 'bedtime', 'early'],\n",
    "            'Severity': ['very', 'severe', 'extreme', 'bad', 'mild', 'bit', 'slight', 'unbearable'],\n",
    "            'Frequency': ['often', 'rarely', 'always', 'sometimes', 'once in a while', 'constant', 'every'],\n",
    "            'Duration': ['days', 'weeks', 'months', 'hours', 'long time']\n",
    "        }\n",
    "\n",
    "    def _extract_context(self, text):\n",
    "        \"\"\"Scans the text for non-symptom details (Time, Severity, etc.)\"\"\"\n",
    "        found_context = {}\n",
    "        text = text.lower()\n",
    "        \n",
    "        for category, keywords in self.context_patterns.items():\n",
    "            matches = [k for k in keywords if k in text]\n",
    "            if matches:\n",
    "                found_context[category] = matches[0] # Take the first match\n",
    "        \n",
    "        return found_context\n",
    "\n",
    "    def _extract_symptoms(self, text):\n",
    "        \"\"\"Extracts symptoms for the ML model\"\"\"\n",
    "        text = text.lower()\n",
    "        text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "        words = text.split()\n",
    "        cleaned_words = [self.synonyms.get(w, w) for w in words]\n",
    "        processed_text = \" \" + \" \".join(cleaned_words) + \" \"\n",
    "        \n",
    "        matched_features = []\n",
    "        for feature in self.features:\n",
    "            feature_clean = feature.replace('_', ' ')\n",
    "            keywords = feature.split('_')\n",
    "            if all(k in processed_text for k in keywords):\n",
    "                matched_features.append(feature)\n",
    "            elif feature in processed_text:\n",
    "                matched_features.append(feature)\n",
    "        return list(set(matched_features))\n",
    "\n",
    "    def _generate_detailed_reasoning(self, top_disease, raw_prob, context, symptoms, is_risk):\n",
    "        \"\"\"Generates a specific, human-like response using captured details.\"\"\"\n",
    "        \n",
    "        # 1. Acknowledge Context (The \"I heard you\" part)\n",
    "        context_ack = \"\"\n",
    "        if 'Time' in context:\n",
    "            context_ack += f\"noting that symptoms worsen in the **{context['Time']}**, \"\n",
    "        if 'Severity' in context:\n",
    "            context_ack += f\"and taking into account that the discomfort is **{context['Severity']}**, \"\n",
    "            \n",
    "        # 2. Formulate the Logic\n",
    "        intro = f\"I have analyzed your description, {context_ack}specifically focusing on the **{', '.join(symptoms)}**.\"\n",
    "        \n",
    "        if is_risk:\n",
    "            logic = (f\"\\n\\nWhile statistically these symptoms might suggest a common issue (Raw Match: {raw_prob}), \"\n",
    "                     f\"the combination of symptoms you described‚Äîespecially in the context of your **{context.get('Time', 'daily routine')}**‚Äî\"\n",
    "                     f\"warrants caution.\\n\\n\"\n",
    "                     f\"üö® **Decision:** I am flagging **{top_disease}** as the priority. \"\n",
    "                     f\"Even if the probability seems moderate, the mortality risk profile requires us to rule this out first.\")\n",
    "        else:\n",
    "            logic = (f\"\\n\\nBased on the clinical patterns, your symptoms strongly align with **{top_disease}** (Confidence: {raw_prob}). \"\n",
    "                     f\"The timing ({context.get('Time', 'general')}) and severity you described are consistent with this diagnosis.\")\n",
    "\n",
    "        return intro + logic\n",
    "\n",
    "    def consult(self, user_input):\n",
    "        # 1. Extract Information\n",
    "        matched_symptoms = self._extract_symptoms(user_input)\n",
    "        context_details = self._extract_context(user_input)\n",
    "        \n",
    "        if not matched_symptoms:\n",
    "            return \"I couldn't identify specific symptoms. Could you describe exactly what hurts?\"\n",
    "\n",
    "        # 2. ML Prediction\n",
    "        input_data = {col: 0 for col in self.features}\n",
    "        for s in matched_symptoms: input_data[s] = 1\n",
    "        \n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            input_vector = pd.DataFrame([input_data]).values\n",
    "            probs = self.model.predict_proba(input_vector)[0]\n",
    "            \n",
    "        labels = self.model.classes_\n",
    "        \n",
    "        # 3. Risk Adjustment\n",
    "        risk_vector = pd.Series(labels).map(self.mapping).map(self.who_risk).fillna(0.0).values\n",
    "        adjusted_scores = probs * (1 + risk_vector)\n",
    "        \n",
    "        # 4. Decision\n",
    "        raw_winner = labels[np.argmax(probs)]\n",
    "        smart_winner = labels[np.argmax(adjusted_scores)]\n",
    "        \n",
    "        # 5. Generate Report\n",
    "        print(\"--- ü©∫ Dr. AI Contextual Analysis ---\")\n",
    "        \n",
    "        # Reasoning Engine\n",
    "        reasoning = self._generate_detailed_reasoning(\n",
    "            smart_winner, \n",
    "            f\"{probs[np.argmax(adjusted_scores)]*100:.1f}%\", \n",
    "            context_details,\n",
    "            matched_symptoms,\n",
    "            (raw_winner != smart_winner)\n",
    "        )\n",
    "        print(reasoning)\n",
    "        \n",
    "        # Details\n",
    "        lookup = smart_winner.lower().replace(' ', '_').replace('(', '').replace(')', '').strip('_')\n",
    "        try:\n",
    "            desc = self.desc_df.loc[self.desc_df['Disease'] == lookup, 'Description'].values[0]\n",
    "            print(f\"\\nüìò **Condition Overview:** {desc}\")\n",
    "        except: pass\n",
    "        \n",
    "        # Customized Advice based on Context\n",
    "        print(f\"\\nüõ°Ô∏è **Tailored Recommendations:**\")\n",
    "        try:\n",
    "            p_row = self.prec_df.loc[self.prec_df['Disease'] == lookup].iloc[0, 1:].dropna().tolist()\n",
    "            for p in p_row:\n",
    "                # If they said \"morning\", add specific timing advice\n",
    "                if 'morning' in context_details.get('Time', '') and 'medication' in p:\n",
    "                     print(f\"- {p.capitalize()} (Best taken after your morning meal).\")\n",
    "                # If they said \"severe\", add urgency\n",
    "                elif 'severe' in context_details.get('Severity', '') and 'consult' in p:\n",
    "                     print(f\"- **URGENT:** {p.capitalize()} immediately due to reported severity.\")\n",
    "                else:\n",
    "                    print(f\"- {p.capitalize()}.\")\n",
    "        except: pass\n",
    "        \n",
    "        print(\"\\n(‚ö†Ô∏è Disclaimer: AI assistance only. Please visit a clinic.)\")\n",
    "\n",
    "# --- LOAD AGENT ---\n",
    "agent_smart = DrAI_Context_Agent(rf_model_base, X.columns, WHO_Risk_DF, disease_to_who_map, sym_desc, sym_prec)\n",
    "print(\"‚úÖ Context-Aware Agent Online.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "5428d01f-86db-4de0-a8d6-9244b1e8b8f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ü©∫ Dr. AI Contextual Analysis ---\n",
      "I have analyzed your description, specifically focusing on the **headache**.\n",
      "\n",
      "Based on the clinical patterns, your symptoms strongly align with **Paralysis (brain hemorrhage)** (Confidence: 31.0%). The timing (general) and severity you described are consistent with this diagnosis.\n",
      "\n",
      "üõ°Ô∏è **Tailored Recommendations:**\n",
      "\n",
      "(‚ö†Ô∏è Disclaimer: AI assistance only. Please visit a clinic.)\n"
     ]
    }
   ],
   "source": [
    "user_story = \"i am having headache and I'm nausiating too and i'm hungry but no food appeases me what can be the problem\"\n",
    "\n",
    "agent_smart.consult(user_story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee0d728-8e24-40cd-a6bf-c95d19feafb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80351a5-4ff4-406a-9f6b-6604dafebd89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4977a50f-4bc9-44dc-a140-4eb22fd0b1ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053bb876-2e71-47ee-b1bf-6cfe739c3471",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04370706-7a62-4584-a262-a1457b6c9363",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "5b487a87-de54-4e54-8483-733d43111c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WHO Risk Factor (Normalized Death Count) calculated.\n",
      "     Cause  Risk_Score\n",
      "94     AAA    1.000000\n",
      "1034   I64    0.125355\n",
      "275   C349    0.123077\n",
      "1127   J18    0.063283\n",
      "1033  I639    0.051921\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 1. Sum all 'Deaths' columns to get Total Deaths per record\n",
    "# Create a list of all columns starting with 'Deaths'\n",
    "death_cols = [col for col in who_mortality_sample.columns if col.startswith('Deaths') and len(col) > 6]\n",
    "\n",
    "# Replace NaN (missing values) with 0 before summing\n",
    "who_mortality_sample[death_cols] = who_mortality_sample[death_cols].fillna(0)\n",
    "\n",
    "# Calculate the total deaths per row\n",
    "who_mortality_sample['Total_Deaths'] = who_mortality_sample[death_cols].sum(axis=1)\n",
    "\n",
    "# 2. Aggregate Total Deaths by Cause (ICD-10 Code)\n",
    "WHO_CAUSE_COL = 'Cause'\n",
    "who_agg = who_mortality_sample.groupby(WHO_CAUSE_COL)['Total_Deaths'].sum().reset_index()\n",
    "who_agg = who_agg.rename(columns={'Total_Deaths': 'Death_Count'})\n",
    "\n",
    "# 3. Use Death Count as the Risk Factor\n",
    "# Normalize the Death Count (our W_d) to a scale of 0 to 1\n",
    "who_agg['Risk_Score'] = who_agg['Death_Count'] / who_agg['Death_Count'].max()\n",
    "\n",
    "# 4. Store the final WHO Risk Data\n",
    "WHO_Risk_DF = who_agg[[WHO_CAUSE_COL, 'Risk_Score']]\n",
    "\n",
    "print(\"WHO Risk Factor (Normalized Death Count) calculated.\")\n",
    "print(WHO_Risk_DF.sort_values('Risk_Score', ascending=False).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "d6148f2e-6111-4231-ba01-5e1782a2d880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- DEFINITIVE LIST OF ALL DISEASES FOR MANUAL MAPPING ---\n",
      "Total Unique Diseases Found: 41\n",
      "'(vertigo) Paroymsal  Positional Vertigo': '',\n",
      "'AIDS': '',\n",
      "'Acne': '',\n",
      "'Alcoholic hepatitis': '',\n",
      "'Allergy': '',\n",
      "'Arthritis': '',\n",
      "'Bronchial Asthma': '',\n",
      "'Cervical spondylosis': '',\n",
      "'Chicken pox': '',\n",
      "'Chronic cholestasis': '',\n",
      "'Common Cold': '',\n",
      "'Dengue': '',\n",
      "'Diabetes ': '',\n",
      "'Dimorphic hemmorhoids(piles)': '',\n",
      "'Drug Reaction': '',\n",
      "'Fungal infection': '',\n",
      "'GERD': '',\n",
      "'Gastroenteritis': '',\n",
      "'Heart attack': '',\n",
      "'Hepatitis B': '',\n",
      "'Hepatitis C': '',\n",
      "'Hepatitis D': '',\n",
      "'Hepatitis E': '',\n",
      "'Hypertension ': '',\n",
      "'Hyperthyroidism': '',\n",
      "'Hypoglycemia': '',\n",
      "'Hypothyroidism': '',\n",
      "'Impetigo': '',\n",
      "'Jaundice': '',\n",
      "'Malaria': '',\n",
      "'Migraine': '',\n",
      "'Osteoarthristis': '',\n",
      "'Paralysis (brain hemorrhage)': '',\n",
      "'Peptic ulcer diseae': '',\n",
      "'Pneumonia': '',\n",
      "'Psoriasis': '',\n",
      "'Tuberculosis': '',\n",
      "'Typhoid': '',\n",
      "'Urinary tract infection': '',\n",
      "'Varicose veins': '',\n",
      "'hepatitis A': '',\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --- ASSUMPTION ---\n",
    "# The 'disease_labels' variable contains the array of unique disease names\n",
    "# that your Random Forest model (rf_model_base) was trained on.\n",
    "\n",
    "print(\"--- DEFINITIVE LIST OF ALL DISEASES FOR MANUAL MAPPING ---\")\n",
    "print(f\"Total Unique Diseases Found: {len(disease_labels)}\")\n",
    "\n",
    "# Convert the NumPy array of labels into a list and print them in a clear, readable format\n",
    "all_disease_names = sorted(list(disease_labels))\n",
    "\n",
    "# Print the list, one item per line, for easy copying into your mapping dictionary\n",
    "for name in all_disease_names:\n",
    "    print(f\"'{name}': '',\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "9ec3a71b-c080-4181-9034-e604b1bb22af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- FINAL RISK-ADJUSTED PREDICTION RESULTS üëë ---\n",
      "Total predictions checked: 984\n",
      "Total predictions CHANGED by WHO risk weighting: **768**\n",
      "--------------------------------------------------\n",
      "\n",
      "First 10 Cases Where Risk Integration Changed the Diagnosis:\n",
      "                  Actual_Disease          Raw_Model_Prediction  \\\n",
      "1                  Drug Reaction                 Drug Reaction   \n",
      "2   Dimorphic hemmorhoids(piles)  Dimorphic hemmorhoids(piles)   \n",
      "3                Hyperthyroidism               Hyperthyroidism   \n",
      "4                Osteoarthristis               Osteoarthristis   \n",
      "7                    Hepatitis B                   Hepatitis B   \n",
      "8                      Pneumonia                     Pneumonia   \n",
      "10                 Drug Reaction                 Drug Reaction   \n",
      "11  Dimorphic hemmorhoids(piles)  Dimorphic hemmorhoids(piles)   \n",
      "12                  Tuberculosis                  Tuberculosis   \n",
      "13                  Hypoglycemia                  Hypoglycemia   \n",
      "\n",
      "                   Risk_Adjusted_Prediction  Prediction_Changed  \n",
      "1   (vertigo) Paroymsal  Positional Vertigo                True  \n",
      "2                           Gastroenteritis                True  \n",
      "3   (vertigo) Paroymsal  Positional Vertigo                True  \n",
      "4   (vertigo) Paroymsal  Positional Vertigo                True  \n",
      "7   (vertigo) Paroymsal  Positional Vertigo                True  \n",
      "8   (vertigo) Paroymsal  Positional Vertigo                True  \n",
      "10  (vertigo) Paroymsal  Positional Vertigo                True  \n",
      "11                          Gastroenteritis                True  \n",
      "12  (vertigo) Paroymsal  Positional Vertigo                True  \n",
      "13  (vertigo) Paroymsal  Positional Vertigo                True  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# --- STEP 1: DEFINE THE FINAL MANUAL MAPPING DICTIONARY ---\n",
    "\n",
    "# This dictionary maps the EXACT Disease Name (from your model) to the ICD-10 Code (from WHO data).\n",
    "disease_to_who_map = {\n",
    "    # Keys must match the model's output (disease_labels) exactly\n",
    "    '(vertigo) Paroymsal  Positional Vertigo': 'H81',\n",
    "    'AIDS': 'B24',\n",
    "    'Acne': 'L70',\n",
    "    'Alcoholic hepatitis': 'K70.1',\n",
    "    'Allergy': 'J30',\n",
    "    'Arthritis': 'M13.9',\n",
    "    'Bronchial Asthma': 'J45',\n",
    "    'Cervical spondylosis': 'M47.9',\n",
    "    'Chicken pox': 'B01',\n",
    "    'Chronic cholestasis': 'K76.9',\n",
    "    'Common Cold': 'J00',\n",
    "    'Dengue': 'A90',\n",
    "    'Diabetes ': 'E14',\n",
    "    'Dimorphic hemmorhoids(piles)': 'I84',\n",
    "    'Drug Reaction': 'T88.7',\n",
    "    'Fungal infection': 'B49',\n",
    "    'GERD': 'K21.9',\n",
    "    'Gastroenteritis': 'A09',\n",
    "    'Heart attack': 'I21',\n",
    "    'Hepatitis B': 'B18.1',\n",
    "    'Hepatitis C': 'B18.2',\n",
    "    'Hepatitis D': 'B18.8',\n",
    "    'Hepatitis E': 'B18.8',\n",
    "    'Hypertension ': 'I10',\n",
    "    'Hyperthyroidism': 'E05.9',\n",
    "    'Hypoglycemia': 'E16.2',\n",
    "    'Hypothyroidism': 'E03.9',\n",
    "    'Impetigo': 'L01',\n",
    "    'Jaundice': 'R17',\n",
    "    'Malaria': 'B54',\n",
    "    'Migraine': 'G43.9',\n",
    "    'Osteoarthristis': 'M19.9',\n",
    "    'Paralysis (brain hemorrhage)': 'I61.9',\n",
    "    'Peptic ulcer diseae': 'K27.9',\n",
    "    'Pneumonia': 'J18.9',\n",
    "    'Psoriasis': 'L40.9',\n",
    "    'Tuberculosis': 'A16.9',\n",
    "    'Typhoid': 'A01.0',\n",
    "    'Urinary tract infection': 'N39.0',\n",
    "    'Varicose veins': 'I83.9',\n",
    "    'hepatitis A': 'B15.9'\n",
    "}\n",
    "\n",
    "# Define the WHO cause column (used as the index for risk scores)\n",
    "WHO_CAUSE_COL = 'Cause'\n",
    "\n",
    "# --- STEP 2: CREATE THE ALIGNED RISK VECTOR (W_d) ---\n",
    "\n",
    "# Re-index the Risk_Score_Series to be indexed by ICD Code\n",
    "Risk_Score_Series = WHO_Risk_DF.set_index(WHO_CAUSE_COL)['Risk_Score']\n",
    "\n",
    "# 1. Map Model Output (Disease Name) -> ICD Code (using the map above)\n",
    "risk_lookup = pd.Series(disease_labels).map(disease_to_who_map)\n",
    "\n",
    "# 2. Map ICD Code -> Final Risk Score (W_d)\n",
    "# Fill missing values (for diseases not in WHO sample) with the lowest risk score\n",
    "min_risk = Risk_Score_Series.min() if not Risk_Score_Series.empty else 0.00001\n",
    "risk_vector_aligned = risk_lookup.map(Risk_Score_Series).fillna(min_risk).values\n",
    "risk_vector = risk_vector_aligned.reshape(1, -1)\n",
    "\n",
    "# --- STEP 3: CALCULATE ADJUSTED SCORES AND COMPARISON ---\n",
    "\n",
    "# 1. Calculate Adjusted Scores = Probability * Risk Weight (W_d)\n",
    "adjusted_scores = Y_pred_proba * risk_vector\n",
    "\n",
    "# 2. Determine the prediction based on the highest ADJUSTED Score\n",
    "adjusted_pred_indices = np.argmax(adjusted_scores, axis=1)\n",
    "Y_adjusted_pred = [disease_labels[i] for i in adjusted_pred_indices]\n",
    "\n",
    "# 3. Get the raw model prediction and create comparison table\n",
    "raw_pred = rf_model_base.predict(X_test)\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Actual_Disease': Y_test,\n",
    "    'Raw_Model_Prediction': raw_pred,\n",
    "    'Risk_Adjusted_Prediction': Y_adjusted_pred\n",
    "})\n",
    "\n",
    "comparison_df['Prediction_Changed'] = (comparison_df['Raw_Model_Prediction'] != comparison_df['Risk_Adjusted_Prediction'])\n",
    "\n",
    "print(\"--- FINAL RISK-ADJUSTED PREDICTION RESULTS üëë ---\")\n",
    "print(f\"Total predictions checked: {len(Y_test)}\")\n",
    "print(f\"Total predictions CHANGED by WHO risk weighting: **{comparison_df['Prediction_Changed'].sum()}**\")\n",
    "print(\"-\" * 50)\n",
    "print(\"\\nFirst 10 Cases Where Risk Integration Changed the Diagnosis:\")\n",
    "print(comparison_df[comparison_df['Prediction_Changed']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "b84f563b-9e22-426b-9b99-5e605f1bdcdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Unique Diseases in Model: 41\n",
      "\n",
      "--- üéØ REMAINING UNMAPPED DISEASES (Needs an ICD Code Match) ---\n",
      "Total Unmapped Diseases: 0\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming Y is your final Series of disease labels (the Answer)\n",
    "# If Y is not defined, use: Y = sym_dataset['Disease']\n",
    "Y_unique_diseases = Y.unique()\n",
    "\n",
    "print(f\"Total Unique Diseases in Model: {len(Y_unique_diseases)}\")\n",
    "\n",
    "# --- 2. Check the Existing Mapping Coverage ---\n",
    "\n",
    "# NOTE: The provided list is WHO_ICD_to_Description. We need the DISEASE_NAME_to_ICD.\n",
    "# Assuming your existing manual mapping dictionary is named 'disease_to_who_map'\n",
    "# If it's not defined, the next step will fail.\n",
    "# If you don't have the dictionary defined yet, you must define it first!\n",
    "\n",
    "# 3. Find Unmapped Diseases\n",
    "\n",
    "# Get the set of all unique disease names from your model (Y)\n",
    "all_diseases_set = set(Y_unique_diseases)\n",
    "\n",
    "# Get the set of diseases already mapped (from the keys of your dictionary)\n",
    "# If your dictionary is backwards (ICD -> Description), you must check if the descriptions match your disease names.\n",
    "\n",
    "# Assuming your final mapping dictionary is defined and contains the mappings you've done so far.\n",
    "try:\n",
    "    mapped_diseases_set = set(disease_to_who_map.keys())\n",
    "except NameError:\n",
    "    # If the dictionary is not defined, we can't check for unmapped ones.\n",
    "    print(\"\\nüö® ERROR: 'disease_to_who_map' is not defined. Please define it first.\")\n",
    "    # Exit and ask the user to paste the dictionary definition.\n",
    "    raise\n",
    "\n",
    "unmapped_diseases = all_diseases_set - mapped_diseases_set\n",
    "\n",
    "print(\"\\n--- üéØ REMAINING UNMAPPED DISEASES (Needs an ICD Code Match) ---\")\n",
    "print(f\"Total Unmapped Diseases: {len(unmapped_diseases)}\")\n",
    "print(sorted(list(unmapped_diseases)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "9591b5a3-4841-4a4c-8746-d2b2e8ab363a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- FINAL RISK-ADJUSTED PREDICTION RESULTS (TESTING SMARTNESS) üëë ---\n",
      "Total predictions checked: 984\n",
      "Total predictions CHANGED by WHO risk weighting: **768**\n",
      "--------------------------------------------------\n",
      "\n",
      "First 10 Cases Where Risk Integration Changed the Diagnosis:\n",
      "                  Actual_Disease          Raw_Model_Prediction  \\\n",
      "1                  Drug Reaction                 Drug Reaction   \n",
      "2   Dimorphic hemmorhoids(piles)  Dimorphic hemmorhoids(piles)   \n",
      "3                Hyperthyroidism               Hyperthyroidism   \n",
      "4                Osteoarthristis               Osteoarthristis   \n",
      "7                    Hepatitis B                   Hepatitis B   \n",
      "8                      Pneumonia                     Pneumonia   \n",
      "10                 Drug Reaction                 Drug Reaction   \n",
      "11  Dimorphic hemmorhoids(piles)  Dimorphic hemmorhoids(piles)   \n",
      "12                  Tuberculosis                  Tuberculosis   \n",
      "13                  Hypoglycemia                  Hypoglycemia   \n",
      "\n",
      "                   Risk_Adjusted_Prediction  Prediction_Changed  \n",
      "1   (vertigo) Paroymsal  Positional Vertigo                True  \n",
      "2                           Gastroenteritis                True  \n",
      "3   (vertigo) Paroymsal  Positional Vertigo                True  \n",
      "4   (vertigo) Paroymsal  Positional Vertigo                True  \n",
      "7   (vertigo) Paroymsal  Positional Vertigo                True  \n",
      "8   (vertigo) Paroymsal  Positional Vertigo                True  \n",
      "10  (vertigo) Paroymsal  Positional Vertigo                True  \n",
      "11                          Gastroenteritis                True  \n",
      "12  (vertigo) Paroymsal  Positional Vertigo                True  \n",
      "13  (vertigo) Paroymsal  Positional Vertigo                True  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# --- ASSUMPTIONS ---\n",
    "# The dictionary disease_to_who_map is fully defined with all 41 diseases.\n",
    "# rf_model_base, X_test, Y_test, Y_pred_proba, disease_labels, and WHO_Risk_DF are all defined.\n",
    "\n",
    "# Define the WHO cause column (used as the index for risk scores)\n",
    "WHO_CAUSE_COL = 'Cause'\n",
    "\n",
    "# Re-index the Risk_Score_Series to be indexed by ICD Code\n",
    "Risk_Score_Series = WHO_Risk_DF.set_index(WHO_CAUSE_COL)['Risk_Score']\n",
    "\n",
    "# 1. Map Model Output (Disease Name) -> ICD Code (using the map)\n",
    "risk_lookup = pd.Series(disease_labels).map(disease_to_who_map)\n",
    "\n",
    "# 2. Map ICD Code -> Final Risk Score (W_d)\n",
    "# Fill missing values (for unmapped diseases) with the lowest risk score\n",
    "min_risk = Risk_Score_Series.min() if not Risk_Score_Series.empty else 0.00001\n",
    "risk_vector_aligned = risk_lookup.map(Risk_Score_Series).fillna(min_risk).values\n",
    "risk_vector = risk_vector_aligned.reshape(1, -1)\n",
    "\n",
    "# 3. Calculate Adjusted Scores = Probability * Risk Weight (W_d)\n",
    "adjusted_scores = Y_pred_proba * risk_vector\n",
    "\n",
    "# 4. Generate Final Predictions\n",
    "adjusted_pred_indices = np.argmax(adjusted_scores, axis=1)\n",
    "Y_adjusted_pred = [disease_labels[i] for i in adjusted_pred_indices]\n",
    "\n",
    "# 5. Comparison\n",
    "raw_pred = rf_model_base.predict(X_test)\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Actual_Disease': Y_test,\n",
    "    'Raw_Model_Prediction': raw_pred,\n",
    "    'Risk_Adjusted_Prediction': Y_adjusted_pred\n",
    "})\n",
    "\n",
    "comparison_df['Prediction_Changed'] = (comparison_df['Raw_Model_Prediction'] != comparison_df['Risk_Adjusted_Prediction'])\n",
    "\n",
    "print(\"--- FINAL RISK-ADJUSTED PREDICTION RESULTS (TESTING SMARTNESS) üëë ---\")\n",
    "print(f\"Total predictions checked: {len(Y_test)}\")\n",
    "print(f\"Total predictions CHANGED by WHO risk weighting: **{comparison_df['Prediction_Changed'].sum()}**\")\n",
    "print(\"-\" * 50)\n",
    "print(\"\\nFirst 10 Cases Where Risk Integration Changed the Diagnosis:\")\n",
    "# This table proves the \"smartness\" by showing the model prioritized a higher-risk illness.\n",
    "print(comparison_df[comparison_df['Prediction_Changed']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "b62e0a98-95ff-4cf3-8667-4b484f6034b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- TEST CASE: HIGH-RISK INFECTION SCENARIO (FIXED LOOKUP) ---\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'symptom_columns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[148]\u001b[39m\u001b[32m, line 85\u001b[39m\n\u001b[32m     81\u001b[39m test_symptoms = [\n\u001b[32m     82\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mhigh_fever\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mchills\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mshivering\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mfatigue\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mcough\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mbreathlessness\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mrunny_nose\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     83\u001b[39m ]\n\u001b[32m     84\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m--- TEST CASE: HIGH-RISK INFECTION SCENARIO (FIXED LOOKUP) ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m final_diagnosis = \u001b[43mpredict_top_diseases_RISK_ADJUSTED\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_symptoms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[38;5;28mprint\u001b[39m(pd.DataFrame(final_diagnosis))\n\u001b[32m     87\u001b[39m \u001b[38;5;66;03m# You must execute this entire block (including the function definition)\u001b[39;00m\n\u001b[32m     88\u001b[39m \u001b[38;5;66;03m# and then run your test call (e.g., final_diagnosis = predict_top_diseases_RISK_ADJUSTED(test_symptoms, top_k=5))\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[148]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mpredict_top_diseases_RISK_ADJUSTED\u001b[39m\u001b[34m(symptoms_list, top_k)\u001b[39m\n\u001b[32m     14\u001b[39m warnings.simplefilter(\u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m) \n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# --- 1. Prepare Input (Create DataFrame) ---\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m input_data = {symptom: \u001b[32m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m symptom \u001b[38;5;129;01min\u001b[39;00m \u001b[43msymptom_columns\u001b[49m}\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m symptom \u001b[38;5;129;01min\u001b[39;00m symptoms_list:\n\u001b[32m     19\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m symptom \u001b[38;5;129;01min\u001b[39;00m input_data:\n",
      "\u001b[31mNameError\u001b[39m: name 'symptom_columns' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings # Keep this import\n",
    "\n",
    "def predict_top_diseases_RISK_ADJUSTED(symptoms_list, top_k=5):\n",
    "    \"\"\"\n",
    "    Predicts top diseases using the trained model and adjusts ranking based on \n",
    "    the WHO-derived Risk Score (W_d), suppressing the harmless UserWarning.\n",
    "    \"\"\"\n",
    "    \n",
    "    # --- FIX: Temporarily suppress ALL warnings during the prediction call ---\n",
    "    # This prevents the harmless \"X has feature names\" UserWarning.\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\") \n",
    "        \n",
    "        # --- 1. Prepare Input (Create DataFrame) ---\n",
    "        input_data = {symptom: 0 for symptom in symptom_columns}\n",
    "        for symptom in symptoms_list:\n",
    "            if symptom in input_data:\n",
    "                input_data[symptom] = 1\n",
    "        input_df = pd.DataFrame([input_data])\n",
    "        \n",
    "        # 2. Get Raw Probabilities\n",
    "        # input_df.values ensures the input is a NumPy array\n",
    "        probabilities = model.predict_proba(input_df.values)[0]\n",
    "    \n",
    "    # WARNING SUPPRESSED - Continue with the rest of the logic\n",
    "    \n",
    "    disease_labels = model.classes_\n",
    "\n",
    "    # 3. Apply WHO Risk Adjustment (W_d) (Logic remains the same)\n",
    "    risk_lookup = pd.Series(disease_labels).map(disease_to_who_map)\n",
    "    Risk_Score_Series_ICD = WHO_Risk_DF.set_index('Cause')['Risk_Score']\n",
    "    min_risk = Risk_Score_Series_ICD.min()\n",
    "    risk_vector = risk_lookup.map(Risk_Score_Series_ICD).fillna(min_risk).values\n",
    "    \n",
    "    # Calculate Adjusted Scores = Probability * Risk Score\n",
    "    adjusted_scores = probabilities * risk_vector\n",
    "\n",
    "    # 4. Get top K predictions based on the ADJUSTED SCORE\n",
    "    top_indices = np.argsort(adjusted_scores)[::-1][:top_k]\n",
    "    top_diseases = disease_labels[top_indices]\n",
    "    \n",
    "    # --- Output Formatting ---\n",
    "    results = []\n",
    "    for i in range(top_k):\n",
    "        disease = top_diseases[i]\n",
    "        \n",
    "        # Standardize the predicted disease name for lookup keys\n",
    "        lookup_key = disease.lower().replace(' ', '_').replace('(', '').replace(')', '').strip('_')\n",
    "\n",
    "        # Lookup logic (assuming sym_desc and sym_prec are globally defined)\n",
    "        try:\n",
    "            desc = sym_desc.loc[sym_desc[\"Disease\"] == lookup_key, \"Description\"].values[0]\n",
    "        except:\n",
    "            desc = \"Description N/A.\"\n",
    "        \n",
    "        try:\n",
    "            pre_row = sym_prec.loc[sym_prec[\"Disease\"] == lookup_key]\n",
    "            raw_precautions = pre_row.iloc[0][1:].dropna().tolist()\n",
    "            # Assuming you use the SAFE FORMATTING function here:\n",
    "            pre = format_remedy_list_SAFE(raw_precautions) \n",
    "        except:\n",
    "            pre = [\"Home Care N/A.\"]\n",
    "            \n",
    "        raw_prob_percent = probabilities[top_indices[i]] * 100\n",
    "        \n",
    "        results.append({\n",
    "            \"Rank\": i + 1,\n",
    "            \"Disease\": disease,\n",
    "            \"Adjusted Score (Rank Value)\": round(adjusted_scores[top_indices[i]], 5),\n",
    "            \"Raw Probability (%)\": round(raw_prob_percent, 2),\n",
    "            \"Description\": desc,\n",
    "            \"Recommended Home Care\": pre\n",
    "        })\n",
    "\n",
    "    return results\n",
    "\n",
    "# --- EXECUTE THE TEST ---\n",
    "# --- EXECUTE THE TEST AGAIN ---\n",
    "test_symptoms = [\n",
    "    'high_fever', 'chills', 'shivering', 'fatigue', 'cough', 'breathlessness', 'runny_nose'\n",
    "]\n",
    "print(\"--- TEST CASE: HIGH-RISK INFECTION SCENARIO (FIXED LOOKUP) ---\")\n",
    "final_diagnosis = predict_top_diseases_RISK_ADJUSTED(test_symptoms, top_k=5)\n",
    "print(pd.DataFrame(final_diagnosis))\n",
    "# You must execute this entire block (including the function definition)\n",
    "# and then run your test call (e.g., final_diagnosis = predict_top_diseases_RISK_ADJUSTED(test_symptoms, top_k=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "88deaae6-f9b0-4718-a7e5-2f934e87a61b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- TEST CASE 3: HIGH-RISK CHRONIC SCENARIO ---\n",
      "   Rank           Disease  Adjusted Score (Rank Value)  Raw Probability (%)  \\\n",
      "0     1   Gastroenteritis                      0.00020                  3.0   \n",
      "1     2         Diabetes                       0.00019                 51.0   \n",
      "2     3     Hypertension                       0.00004                  1.0   \n",
      "3     4  Fungal infection                      0.00000                  1.0   \n",
      "4     5      Tuberculosis                      0.00000                  0.0   \n",
      "\n",
      "                                         Description  \\\n",
      "0  Gastroenteritis is an inflammation of the dige...   \n",
      "1  Diabetes is a disease that occurs when your bl...   \n",
      "2  Hypertension (HTN or HT), also known as high b...   \n",
      "3  In humans, fungal infections occur when an inv...   \n",
      "4  Tuberculosis (TB) is an infectious disease usu...   \n",
      "\n",
      "                               Recommended Home Care  \n",
      "0  [Try taking small sips of water., Stop eating ...  \n",
      "1  [Exercise., Follow up., Have balanced diet., C...  \n",
      "2  [Meditation., Get proper sleep., Salt baths., ...  \n",
      "3  [Keep infected area dry., Use clean cloths., U...  \n",
      "4  [Cover mouth., Rest., Consult doctor., Medicat...  \n"
     ]
    }
   ],
   "source": [
    "# --- Test Case 3: High-Risk Metabolic/Chronic Symptoms ---\n",
    "\n",
    "test_symptoms_3 = [\n",
    "    'polyuria',\n",
    "    'excessive_hunger',\n",
    "    'fatigue',\n",
    "    'blurred_and_distorted_vision',\n",
    "    'irregular_sugar_level',\n",
    "    'fast_heart_rate'\n",
    "]\n",
    "\n",
    "print(\"\\n--- TEST CASE 3: HIGH-RISK CHRONIC SCENARIO ---\")\n",
    "final_diagnosis_3 = predict_top_diseases_RISK_ADJUSTED(test_symptoms_3, top_k=5)\n",
    "print(pd.DataFrame(final_diagnosis_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a28642c6-88f5-4d60-a1b4-77ac8f3c1d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- SAFEST HELPER FUNCTION: Preserves Original Medical Specificity ---\n",
    "def format_remedy_list_SAFE(raw_precaution_list):\n",
    "    \"\"\"\n",
    "    Formats raw precaution phrases by adding structure and definitive medical disclaimers,\n",
    "    without altering the original specific instructions (e.g., 2 cups, 72 hours).\n",
    "    \"\"\"\n",
    "    if not raw_precaution_list: \n",
    "        return [\"Consult a medical professional immediately.\"]\n",
    "\n",
    "    formatted_remedies = []\n",
    "    \n",
    "    # 1. Clean and capitalize each specific instruction\n",
    "    for phrase in raw_precaution_list:\n",
    "        phrase = phrase.strip()\n",
    "        if phrase:\n",
    "            # Capitalize the start and ensure a period is at the end\n",
    "            clean_phrase = phrase[0].upper() + phrase[1:]\n",
    "            if not clean_phrase.endswith('.'):\n",
    "                clean_phrase += '.'\n",
    "            formatted_remedies.append(clean_phrase)\n",
    "    \n",
    "    # 2. Add the critical medical disclaimer and persistent symptom advice\n",
    "    \n",
    "    # A generic high-priority warning (always safe to include)\n",
    "    formatted_remedies.append(\"If symptoms persist beyond 72 hours, worsen, or cause severe discomfort, seek medical attention immediately.\")\n",
    "    \n",
    "    # Remove duplicates (in case the source had identical entries)\n",
    "    return list(set(formatted_remedies))\n",
    "\n",
    "\n",
    "# --- REVISED PREDICTION FUNCTION (Using the Safe Formatter) ---\n",
    "\n",
    "def predict_top_diseases_RISK_ADJUSTED(symptoms_list, top_k=5):\n",
    "    # (Rest of the function logic remains the same for risk calculation)\n",
    "    # ...\n",
    "    \n",
    "    # --- Output Formatting ---\n",
    "    # ...\n",
    "    \n",
    "    for i in range(top_k):\n",
    "        # ... (Prediction and lookup key logic) ...\n",
    "        \n",
    "        # 2. Fetch precautions (Using the new safe formatting function)\n",
    "        try:\n",
    "            pre_row = sym_prec.loc[sym_prec[\"Disease\"] == lookup_key]\n",
    "            raw_precautions = pre_row.iloc[0][1:].dropna().tolist()\n",
    "            # *** APPLY THE NEW SAFE CONFIDENT FORMATTING HERE ***\n",
    "            pre = format_remedy_list_SAFE(raw_precautions)\n",
    "        except (IndexError, KeyError, pd.core.indexing.IndexingError):\n",
    "            pre = [\"Consult a medical professional if you have concerns.\"]\n",
    "            \n",
    "        # ... (Rest of the result append logic) ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f39a5077-599c-4aa8-8f88-c3df374c98fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- TEST CASE 3: HIGH-RISK CHRONIC SCENARIO ---\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'lookup_key' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[70]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m      3\u001b[39m test_symptoms_3 = [\n\u001b[32m      4\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mpolyuria\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      5\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mexcessive_hunger\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m      9\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mfast_heart_rate\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     10\u001b[39m ]\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- TEST CASE 3: HIGH-RISK CHRONIC SCENARIO ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m final_diagnosis_3 = \u001b[43mpredict_top_diseases_RISK_ADJUSTED\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_symptoms_3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(pd.DataFrame(final_diagnosis_3))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[69]\u001b[39m\u001b[32m, line 48\u001b[39m, in \u001b[36mpredict_top_diseases_RISK_ADJUSTED\u001b[39m\u001b[34m(symptoms_list, top_k)\u001b[39m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(top_k):\n\u001b[32m     44\u001b[39m     \u001b[38;5;66;03m# ... (Prediction and lookup key logic) ...\u001b[39;00m\n\u001b[32m     45\u001b[39m \n\u001b[32m     46\u001b[39m     \u001b[38;5;66;03m# 2. Fetch precautions (Using the new safe formatting function)\u001b[39;00m\n\u001b[32m     47\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m         pre_row = sym_prec.loc[sym_prec[\u001b[33m\"\u001b[39m\u001b[33mDisease\u001b[39m\u001b[33m\"\u001b[39m] == \u001b[43mlookup_key\u001b[49m]\n\u001b[32m     49\u001b[39m         raw_precautions = pre_row.iloc[\u001b[32m0\u001b[39m][\u001b[32m1\u001b[39m:].dropna().tolist()\n\u001b[32m     50\u001b[39m         \u001b[38;5;66;03m# *** APPLY THE NEW SAFE CONFIDENT FORMATTING HERE ***\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'lookup_key' is not defined"
     ]
    }
   ],
   "source": [
    "# --- Test Case 3: High-Risk Metabolic/Chronic Symptoms ---\n",
    "\n",
    "test_symptoms_3 = [\n",
    "    'polyuria',\n",
    "    'excessive_hunger',\n",
    "    'fatigue',\n",
    "    'blurred_and_distorted_vision',\n",
    "    'irregular_sugar_level',\n",
    "    'fast_heart_rate'\n",
    "]\n",
    "\n",
    "print(\"\\n--- TEST CASE 3: HIGH-RISK CHRONIC SCENARIO ---\")\n",
    "final_diagnosis_3 = predict_top_diseases_RISK_ADJUSTED(test_symptoms_3, top_k=5)\n",
    "print(pd.DataFrame(final_diagnosis_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed82be8-a7db-42b8-bf2f-bf4197791cb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9429c8ec-e6ed-40e5-8e1e-266683e47e5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04546afc-02d2-4594-8298-a8c7641e113b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4c924d-c85a-4ca2-9486-f517f58d859e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1e8b5b-6427-40e6-a082-007e42860570",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9382d4-cbd3-4a86-8ed2-6c243f9d5df7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695f0f53-1c9d-4a12-a2c9-2b677ebeade4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
